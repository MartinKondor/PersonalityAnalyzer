{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Myersâ€“Briggs personality type predictor\n",
    "\n",
    "Using the dataset from: [https://www.kaggle.com/datasnaek/mbti-type](https://www.kaggle.com/datasnaek/mbti-type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(sentence1, sentence2):\n",
    "    \"\"\"\n",
    "    Calculating the euclidean distance between\n",
    "    two preprocessed sentences.\n",
    "    \"\"\"\n",
    "    s1_normalized = sentence1 / np.linalg.norm(sentence1)\n",
    "    s2_normalized = sentence2 / np.linalg.norm(sentence2)\n",
    "    return np.linalg.norm(s1_normalized - s2_normalized)\n",
    "\n",
    "\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    \n",
    "    def build_analyzer(self, stemmer=None):\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        \n",
    "        if stemmer is None:\n",
    "            stemmer = SnowballStemmer('english')\n",
    "        \n",
    "        return lambda text: (stemmer.stem(w) for w in analyzer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1500  # number of elements to use from the dataset, because of high ram usage  \n",
    "df = shuffle( pd.read_csv('../data/mbti-myers-briggs-personality-types.csv') )[:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7057</th>\n",
       "      <td>ISTJ</td>\n",
       "      <td>'At my work, passive-aggressive behavior is wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'@Macrosapien  I agree with the victim part. W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'6w7  http://youtu.be/jSWIUEV5sPQ|||sx/sp 5w4 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7346</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>'I'm still here when you mention me by name! L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>ISFP</td>\n",
       "      <td>I've spent years trying to learn how to be pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "7057  ISTJ  'At my work, passive-aggressive behavior is wh...\n",
       "3261  INFJ  '@Macrosapien  I agree with the victim part. W...\n",
       "760   ENTJ  '6w7  http://youtu.be/jSWIUEV5sPQ|||sx/sp 5w4 ...\n",
       "7346  ISFP  'I'm still here when you mention me by name! L...\n",
       "8522  ISFP  I've spent years trying to learn how to be pro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_encoder = OneHotEncoder()\n",
    "y = type_encoder.fit_transform( np.array([df['type'].values]).T ).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = StemmedTfidfVectorizer(min_df=1, stop_words='english')\n",
    "X = vectorizer.fit_transform(df['posts'].values).toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/22\n",
      "1200/1200 [==============================] - 1s 598us/step - loss: 0.0550\n",
      "Epoch 2/22\n",
      "1200/1200 [==============================] - 1s 450us/step - loss: 0.0525\n",
      "Epoch 3/22\n",
      "1200/1200 [==============================] - 1s 429us/step - loss: 0.0494\n",
      "Epoch 4/22\n",
      "1200/1200 [==============================] - 1s 423us/step - loss: 0.0441\n",
      "Epoch 5/22\n",
      "1200/1200 [==============================] - 1s 467us/step - loss: 0.0390\n",
      "Epoch 6/22\n",
      "1200/1200 [==============================] - 1s 430us/step - loss: 0.0346\n",
      "Epoch 7/22\n",
      "1200/1200 [==============================] - 1s 433us/step - loss: 0.0309\n",
      "Epoch 8/22\n",
      "1200/1200 [==============================] - 1s 433us/step - loss: 0.0279\n",
      "Epoch 9/22\n",
      "1200/1200 [==============================] - 1s 437us/step - loss: 0.0255\n",
      "Epoch 10/22\n",
      "1200/1200 [==============================] - 1s 442us/step - loss: 0.0234\n",
      "Epoch 11/22\n",
      "1200/1200 [==============================] - 1s 429us/step - loss: 0.0217\n",
      "Epoch 12/22\n",
      "1200/1200 [==============================] - 1s 434us/step - loss: 0.0202\n",
      "Epoch 13/22\n",
      "1200/1200 [==============================] - 1s 438us/step - loss: 0.0188\n",
      "Epoch 14/22\n",
      "1200/1200 [==============================] - 1s 431us/step - loss: 0.0176\n",
      "Epoch 15/22\n",
      "1200/1200 [==============================] - 1s 453us/step - loss: 0.0164\n",
      "Epoch 16/22\n",
      "1200/1200 [==============================] - 1s 441us/step - loss: 0.0153\n",
      "Epoch 17/22\n",
      "1200/1200 [==============================] - 1s 431us/step - loss: 0.0143\n",
      "Epoch 18/22\n",
      "1200/1200 [==============================] - 1s 441us/step - loss: 0.0133\n",
      "Epoch 19/22\n",
      "1200/1200 [==============================] - 1s 438us/step - loss: 0.0125\n",
      "Epoch 20/22\n",
      "1200/1200 [==============================] - 1s 439us/step - loss: 0.0119\n",
      "Epoch 21/22\n",
      "1200/1200 [==============================] - 1s 430us/step - loss: 0.0113\n",
      "Epoch 22/22\n",
      "1200/1200 [==============================] - 1s 445us/step - loss: 0.0109\n",
      "Train score 0.010545929707586766\n",
      "Test score 0.04558929497996966\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adagrad')\n",
    "\n",
    "history = model.fit(x=X_train, y=y_train, verbose=1, epochs=22, shuffle=True)\n",
    "\n",
    "train_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Train score', train_score)\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test score', test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target is ESFP\n",
      "Predicted is ENFP\n",
      "Sample:\n",
      " i can totally relate to this post. my personality, i've been told, is sweet and vivacious but...i'm secretly shy as hell...particularly when it comes to dating. in any case, it depends on who i'm...'\n"
     ]
    }
   ],
   "source": [
    "def predict(X):\n",
    "    global model, vectorizer, type_encoder\n",
    "    \"\"\"\n",
    "    From an unprocessed string predict the class.\n",
    "    \"\"\"\n",
    "    # preprocess input\n",
    "    transformed_input = vectorizer.transform([X]).toarray()\n",
    "    \n",
    "    prediction = model.predict(transformed_input)\n",
    "    \n",
    "    return type_encoder.inverse_transform(prediction)[0][0]\n",
    "\n",
    "\n",
    "# print(' '.join(list(vectorizer.inverse_transform(X[:1])[0])))\n",
    "# print(type_encoder.inverse_transform(y[:1])[0])\n",
    "\n",
    "sample = df['posts'].iloc[-1].split('|||')[-1]\n",
    "print('Target is', df['type'].iloc[-1])\n",
    "print('Predicted is', predict(sample))\n",
    "print('Sample:\\n', sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving models\n",
    "# joblib.dump(vectorizer, '../trained/vectorizer.pkl')\n",
    "# joblib.dump(type_encoder, '../trained/type_encoder.pkl')\n",
    "# model.save('../trained/model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
