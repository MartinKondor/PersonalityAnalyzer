{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Myersâ€“Briggs personality type predictor\n",
    "\n",
    "Using the dataset from: [https://www.kaggle.com/datasnaek/mbti-type](https://www.kaggle.com/datasnaek/mbti-type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/mbti_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type     False\n",
       "posts    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each datapoint is an unprocessed text where different social media posts are separated by the `|||` character.\n",
    "\n",
    "Now, we must distribute the class `yi` of `i` datapoint on the `xi` values which is splited by the `|||` character. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = [], []\n",
    "\n",
    "for xi, yi in zip(df['posts'].values, df['type'].values):\n",
    "    # split at the separator\n",
    "    posts = xi.split('|||')\n",
    "    X.extend(posts)\n",
    "    \n",
    "    # add the class for each posts\n",
    "    for _ in range(len(posts)):\n",
    "        y.append(yi)\n",
    "\n",
    "del df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has\n",
      "72104 \t INFJs \t 17.05 %\n",
      "33760 \t ENTPs \t 7.98 %\n",
      "63358 \t INTPs \t 14.98 %\n",
      "52470 \t INTJs \t 12.41 %\n",
      "11272 \t ENTJs \t 2.67 %\n",
      "9287 \t ENFJs \t 2.2 %\n",
      "89795 \t INFPs \t 21.24 %\n",
      "32768 \t ENFPs \t 7.75 %\n",
      "12999 \t ISFPs \t 3.07 %\n",
      "16497 \t ISTPs \t 3.9 %\n",
      "8120 \t ISFJs \t 1.92 %\n",
      "9912 \t ISTJs \t 2.34 %\n",
      "4336 \t ESTPs \t 1.03 %\n",
      "2214 \t ESFPs \t 0.52 %\n",
      "1920 \t ESTJs \t 0.45 %\n",
      "2017 \t ESFJs \t 0.48 %\n"
     ]
    }
   ],
   "source": [
    "def print_class_dist(y):\n",
    "    classes = {}\n",
    "\n",
    "    for c in y:\n",
    "        if c in classes.keys():\n",
    "            classes[c] += 1\n",
    "        else:\n",
    "            classes[c] = 0\n",
    "\n",
    "    print('The dataset has')\n",
    "\n",
    "    for c in classes:\n",
    "        print(classes[c], '\\t',\n",
    "              c + 's', '\\t',\n",
    "              round(100 * classes[c] / len(y), 2), '%')\n",
    "    return classes\n",
    "\n",
    "classes = print_class_dist(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should regulate classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose max \"class_limit\" rows from each class\n",
    "\n",
    "X_new = []\n",
    "y_new = []\n",
    "class_limit = 1920\n",
    "class_counter = {k: 0 for k in classes.keys()}\n",
    "\n",
    "for xi, yi in zip(X, y):\n",
    "    if class_counter[yi] > class_limit:\n",
    "        continue\n",
    "        \n",
    "    class_counter[yi] += 1\n",
    "    \n",
    "    X_new.append(xi)\n",
    "    y_new.append(yi)\n",
    "    \n",
    "    \n",
    "del X, y\n",
    "X, y = X_new, y_new\n",
    "del X_new, y_new\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has\n",
      "1920 \t INFJs \t 6.25 %\n",
      "1920 \t ENTPs \t 6.25 %\n",
      "1920 \t INTPs \t 6.25 %\n",
      "1920 \t INTJs \t 6.25 %\n",
      "1920 \t ENTJs \t 6.25 %\n",
      "1920 \t ENFJs \t 6.25 %\n",
      "1920 \t INFPs \t 6.25 %\n",
      "1920 \t ENFPs \t 6.25 %\n",
      "1920 \t ISFPs \t 6.25 %\n",
      "1920 \t ISTPs \t 6.25 %\n",
      "1920 \t ISFJs \t 6.25 %\n",
      "1920 \t ISTJs \t 6.25 %\n",
      "1920 \t ESTPs \t 6.25 %\n",
      "1920 \t ESFPs \t 6.25 %\n",
      "1920 \t ESTJs \t 6.25 %\n",
      "1920 \t ESFJs \t 6.25 %\n"
     ]
    }
   ],
   "source": [
    "print_class_dist(y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode target (y) values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "class_encoder = OneHotEncoder()\n",
    "\n",
    "y_encoded = class_encoder.fit_transform(np.array(y).reshape(-1, 1)).toarray()\n",
    "\n",
    "del y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set: (27662,)\n",
      "Size of test set: (3074,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y_encoded), test_size=.1, random_state=0)\n",
    "\n",
    "print('Size of train set:', X_train.shape)\n",
    "print('Size of test set:', X_test.shape)\n",
    "\n",
    "del X, y_encoded\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're a perfectionist yet a procrastinator :tongue:\n",
      "--------------------\n",
      "INFP\n"
     ]
    }
   ],
   "source": [
    "print(X_train[-1])\n",
    "print(20 * '-')\n",
    "print(class_encoder.inverse_transform([y_train[-1]])[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing of the text input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
