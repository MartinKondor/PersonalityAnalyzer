{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Myersâ€“Briggs personality type predictor\n",
    "\n",
    "Using the dataset from: [https://www.kaggle.com/datasnaek/mbti-type](https://www.kaggle.com/datasnaek/mbti-type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distance(sentence1, sentence2):\n",
    "    \"\"\"\n",
    "    Calculating the euclidean distance between\n",
    "    two preprocessed sentences.\n",
    "    \"\"\"\n",
    "    s1_normalized = sentence1 / np.linalg.norm(sentence1)\n",
    "    s2_normalized = sentence2 / np.linalg.norm(sentence2)\n",
    "    return np.linalg.norm(s1_normalized - s2_normalized)\n",
    "\n",
    "\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    \n",
    "    def build_analyzer(self, stemmer=None):\n",
    "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
    "        \n",
    "        if stemmer is None:\n",
    "            stemmer = SnowballStemmer('english')\n",
    "        \n",
    "        return lambda text: (stemmer.stem(w) for w in analyzer(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000  # number of elements to use from the dataset, because of high ram usage  \n",
    "df = shuffle( pd.read_csv('../data/mbti-myers-briggs-personality-types.csv') )[:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'I know what you mean. The way I'm acting at t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6211</th>\n",
       "      <td>ISTP</td>\n",
       "      <td>'Ask questions, don't make statements. The big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5596</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I dream most nights, or at least that's how I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'http://forums.oce.leagueoflegends.com/board/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>ISTP</td>\n",
       "      <td>'I second this idea, you could also add sleepi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts\n",
       "8518  INTJ  'I know what you mean. The way I'm acting at t...\n",
       "6211  ISTP  'Ask questions, don't make statements. The big...\n",
       "5596  INFP  'I dream most nights, or at least that's how I...\n",
       "1459  INTJ  'http://forums.oce.leagueoflegends.com/board/a...\n",
       "5736  ISTP  'I second this idea, you could also add sleepi..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type_encoder = OneHotEncoder()\n",
    "y_encoded = type_encoder.fit_transform( np.array([df['type'].values]).T )\n",
    "y = y_encoded.toarray()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"'I know what you mean. The way I'm acting at the moment is the result of doing what you said and it serving no benefit whatsoever. Well, I tried my hardest anyway.   I have no problem showing...\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = StemmedTfidfVectorizer(min_df=1, stop_words='english')\n",
    "\n",
    "from_nth_column = 7  # get values only before this column\n",
    "new_X = df['posts'].str.split(pat='\\|\\|\\|', expand=True, n=from_nth_column).values\n",
    "new_X[:1][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
